#!/usr/bin/env python
# -*-coding:utf-8 -*-

"""
OSV PyPI æ¶æ„åŒ…ä¸‹è½½å™¨
ä»BigQueryå¯¼å‡ºçš„JSONæ–‡ä»¶ä¸­è§£æå¹¶ä¸‹è½½æ¶æ„åŒ…
"""

import os
import json
import requests
from urllib.parse import urlparse
from collections import defaultdict
from multiprocessing import Pool, Manager, Lock
import time
from concurrent.futures import ThreadPoolExecutor, as_completed


def get_priority(file_path):
    """
    æ ¹æ®æ–‡ä»¶ç±»å‹è¿”å›ä¼˜å…ˆçº§ï¼Œæ•°å­—è¶Šå°ä¼˜å…ˆçº§è¶Šé«˜
    tar.gz ä¼˜å…ˆçº§æœ€é«˜
    """
    if file_path.endswith('.tar.gz'):
        return 0
    elif file_path.endswith('.zip'):
        return 1
    elif file_path.endswith('.whl'):
        return 2
    return 3


def parse_json_file(json_file_path):
    """
    è§£æJSONæ–‡ä»¶ï¼Œæå–åŒ…ä¿¡æ¯å¹¶å»é‡
    """
    print(f"æ­£åœ¨è§£æJSONæ–‡ä»¶: {json_file_path}")
    
    with open(json_file_path, 'r', encoding='utf-8') as f:
        data = json.load(f)
    
    # æŒ‰åŒ…åå’Œç‰ˆæœ¬åˆ†ç»„ï¼Œå»é‡å¤„ç†
    packages = defaultdict(lambda: defaultdict(list))
    
    for item in data:
        package_name = item['name']
        version = item['version']
        path = item['path']
        
        packages[package_name][version].append({
            'path': path,
            'size': item.get('size', 0),
            'upload_time': item.get('upload_time', ''),
            'packagetype': item.get('packagetype', ''),
            'python_version': item.get('python_version', '')
        })
    
    # å»é‡å¤„ç†ï¼šåŒä¸€ä¸ªåŒ…çš„åŒä¸€ä¸ªç‰ˆæœ¬åªä¿ç•™ä¼˜å…ˆçº§æœ€é«˜çš„æ–‡ä»¶
    deduplicated_packages = {}
    
    for package_name, versions in packages.items():
        deduplicated_packages[package_name] = {}
        
        for version, files in versions.items():
            # æŒ‰ä¼˜å…ˆçº§æ’åºï¼Œé€‰æ‹©ä¼˜å…ˆçº§æœ€é«˜çš„æ–‡ä»¶
            sorted_files = sorted(files, key=lambda x: get_priority(x['path']))
            selected_file = sorted_files[0]
            
            deduplicated_packages[package_name][version] = selected_file
            
            print(f"åŒ… {package_name} ç‰ˆæœ¬ {version}: é€‰æ‹©äº† {os.path.basename(selected_file['path'])} "
                  f"(å…±æœ‰ {len(files)} ä¸ªå€™é€‰æ–‡ä»¶)")
    
    return deduplicated_packages


def download_packages(packages_data, download_base_path):
    """
    ä¸‹è½½æ¶æ„åŒ…åˆ°æŒ‡å®šç›®å½•
    """
    print(f"\nå¼€å§‹ä¸‹è½½åŒ…åˆ°ç›®å½•: {download_base_path}")
    
    # åˆ›å»ºåŸºç¡€ä¸‹è½½ç›®å½•
    os.makedirs(download_base_path, exist_ok=True)
    
    total_packages = sum(len(versions) for versions in packages_data.values())
    downloaded_count = 0
    failed_count = 0
    
    print(f"æ€»å…±éœ€è¦ä¸‹è½½ {total_packages} ä¸ªåŒ…æ–‡ä»¶\n")
    
    for package_name, versions in packages_data.items():
        for version, file_info in versions.items():
            file_path = file_info['path']
            full_url = f"https://files.pythonhosted.org/packages/{file_path}"
            
            # åˆ›å»ºä¿å­˜ç›®å½•ï¼šåŒ…å/ç‰ˆæœ¬/
            save_dir = os.path.join(download_base_path, package_name, version)
            os.makedirs(save_dir, exist_ok=True)
            
            # è·å–æ–‡ä»¶å
            file_name = os.path.basename(urlparse(full_url).path)
            save_path = os.path.join(save_dir, file_name)
            
            # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å·²å­˜åœ¨
            if os.path.exists(save_path):
                print(f"â­ï¸  æ–‡ä»¶å·²å­˜åœ¨ï¼Œè·³è¿‡: {package_name}/{version}/{file_name}")
                downloaded_count += 1
                continue
            
            # ä¸‹è½½æ–‡ä»¶
            try:
                print(f"ğŸ“¥ ä¸‹è½½ä¸­: {package_name}/{version}/{file_name}")
                response = requests.get(full_url, timeout=30)
                
                if response.status_code == 200:
                    with open(save_path, 'wb') as f:
                        f.write(response.content)
                    
                    file_size = len(response.content)
                    print(f"âœ… ä¸‹è½½æˆåŠŸ: {save_path} ({file_size} bytes)")
                    downloaded_count += 1
                else:
                    print(f"âŒ ä¸‹è½½å¤±è´¥: {full_url} - HTTP {response.status_code}")
                    failed_count += 1
                    
            except Exception as e:
                print(f"âŒ ä¸‹è½½å¼‚å¸¸: {full_url} - {str(e)}")
                failed_count += 1
    
    print(f"\nğŸ“Š ä¸‹è½½ç»Ÿè®¡:")
    print(f"   âœ… æˆåŠŸ: {downloaded_count}")
    print(f"   âŒ å¤±è´¥: {failed_count}")
    print(f"   ğŸ“¦ æ€»è®¡: {total_packages}")


def print_summary(packages_data):
    """
    æ‰“å°è§£ææ‘˜è¦
    """
    print("\n" + "="*60)
    print("ğŸ“‹ è§£ææ‘˜è¦")
    print("="*60)
    
    total_packages = len(packages_data)
    total_versions = sum(len(versions) for versions in packages_data.values())
    
    print(f"æ€»åŒ…æ•°é‡: {total_packages}")
    print(f"æ€»ç‰ˆæœ¬æ•°é‡: {total_versions}")
    
    # ç»Ÿè®¡æ–‡ä»¶ç±»å‹åˆ†å¸ƒ
    file_types = defaultdict(int)
    for package_name, versions in packages_data.items():
        for version, file_info in versions.items():
            file_path = file_info['path']
            if file_path.endswith('.tar.gz'):
                file_types['tar.gz'] += 1
            elif file_path.endswith('.whl'):
                file_types['whl'] += 1
            elif file_path.endswith('.zip'):
                file_types['zip'] += 1
            else:
                file_types['other'] += 1
    
    print(f"\næ–‡ä»¶ç±»å‹åˆ†å¸ƒ:")
    for file_type, count in sorted(file_types.items()):
        print(f"  {file_type}: {count}")
    
    print("\nå‰10ä¸ªåŒ…:")
    for i, (package_name, versions) in enumerate(list(packages_data.items())[:10], 1):
        version_count = len(versions)
        print(f"  {i:2d}. {package_name} ({version_count} ä¸ªç‰ˆæœ¬)")
    
    print("="*60)


def main():
    """
    ä¸»å‡½æ•°
    """
    print("ğŸš€ OSV PyPI æ¶æ„åŒ…ä¸‹è½½å™¨")
    print("="*60)
    
    # é…ç½®è·¯å¾„
    json_file_path = "/Users/blue/Documents/Github/MalDataCollect/bquxjob_68385913_198931a31a8.json"
    download_base_path = "/Users/blue/Downloads/new_malicious_packages"
    
    print(f"JSONæ–‡ä»¶è·¯å¾„: {json_file_path}")
    print(f"ä¸‹è½½ä¿å­˜è·¯å¾„: {download_base_path}")
    
    # æ£€æŸ¥JSONæ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if not os.path.exists(json_file_path):
        print(f"âŒ JSONæ–‡ä»¶ä¸å­˜åœ¨: {json_file_path}")
        return
    
    print(f"JSONæ–‡ä»¶å­˜åœ¨: {os.path.exists(json_file_path)}")
    print(f"JSONæ–‡ä»¶å¤§å°: {os.path.getsize(json_file_path) / 1024 / 1024:.2f} MB")
    
    try:
        # 1. è§£æJSONæ–‡ä»¶
        packages_data = parse_json_file(json_file_path)
        
        # 2. æ‰“å°æ‘˜è¦
        print_summary(packages_data)
        
        # 3. ä¸‹è½½åŒ…
        download_packages(packages_data, download_base_path)
        
        print(f"\nğŸ‰ ä»»åŠ¡å®Œæˆ!")
        print(f"æ‰€æœ‰æ–‡ä»¶å·²ä¸‹è½½åˆ°: {download_base_path}")
        
    except Exception as e:
        print(f"\nâŒ ç¨‹åºæ‰§è¡Œè¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {str(e)}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main()
